---
layout: post
title: Crash Course - Concurrency and Parallel Programming
date: 2025-10-23 00:00:00 +0000
author: Danny Willems
tags: [concurrency, parallel-programming, rust, computer-architecture]
---

> **Disclaimer**: This content was generated by Claude AI (Anthropic) and has
> not been manually verified for technical accuracy. Please verify critical
> information against authoritative sources before using in production systems.

## Course Overview

This course covers concurrent and parallel programming from first principles to
advanced topics, with a focus on understanding what happens at the hardware
level. We use Rust as our primary language because it makes many concurrency
bugs impossible at compile time.

**Prerequisites**: Basic understanding of assembly, memory hierarchy, and
computer architecture.

---

## Table of Contents

1. [Foundations: The Memory Model](#foundations-the-memory-model)
2. [Hardware Primitives](#hardware-primitives)
3. [Memory Ordering](#memory-ordering)
4. [Atomics and Lock-Free Programming](#atomics-and-lock-free-programming)
5. [Locks and Mutexes](#locks-and-mutexes)
6. [Async/Await and Cooperative Concurrency](#asyncawait-and-cooperative-concurrency)
7. [Deadlocks, Livelocks, and Starvation](#deadlocks-livelocks-and-starvation)
8. [Advanced Topics](#advanced-topics)

---

## Foundations: The Memory Model

### What is Concurrency?

**Concurrency** = Multiple computations happening during overlapping time
periods. They don't have to be simultaneous (that's parallelism).

**Parallelism** = Multiple computations happening at the exact same instant
(requires multiple CPU cores).

```
Concurrent but not parallel:    Parallel (implies concurrent):
Time ->                          Time ->
Thread 1: ---A----B----C----     Thread 1: ---A---B---C---
Thread 2:    --D----E----F---    Thread 2: ---D---E---F---
          (single core)                (multi-core)
```

### The Sequential Consistency Model (Idealized)

In an ideal world, memory operations would appear to execute in some global
sequential order that respects program order:

```rust
// Thread 1
static X: AtomicI32 = AtomicI32::new(0);
static Y: AtomicI32 = AtomicI32::new(0);

// Thread 1
X.store(1, Ordering::SeqCst);  // A
Y.store(1, Ordering::SeqCst);  // B

// Thread 2
let y = Y.load(Ordering::SeqCst);  // C
let x = X.load(Ordering::SeqCst);  // D
```

Under sequential consistency, if y == 1 (C saw B), then x MUST be 1 (D must see
A) because A happens-before B in program order.

**Reality**: Modern CPUs and compilers reorder operations for performance,
breaking this model.

### Why Reordering Happens

1. **Compiler optimizations**: Reorder instructions for better register usage,
   eliminate redundant loads, etc.

2. **CPU out-of-order execution**: Modern CPUs execute instructions out of
   program order for performance.

3. **Store buffers**: Writes go to a per-core buffer before reaching main
   memory.

4. **Cache coherency delays**: Updates to memory take time to propagate between
   cores.

Example of compiler reordering:

```rust
// Original code
let a = shared.load();
let b = shared.load();
expensive_computation();

// Compiler might reorder to:
expensive_computation();
let a = shared.load();
let b = shared.load();
// This is fine for single-threaded code!
```

---

## Hardware Primitives

### CPU Caches and Cache Coherency

Modern CPUs have a hierarchy of caches:

```
Core 0:  L1 Cache (32KB)  <--+
         L2 Cache (256KB) <--+-- Private to core
                             |
         L3 Cache (8MB) <-----+-- Shared between cores
                             |
Core 1:  L1 Cache        <--+
         L2 Cache        <--+

Main Memory (RAM)
```

**Cache line**: The unit of cache coherency, typically 64 bytes. When you
read/write a byte, the entire 64-byte line is loaded.

**False sharing**: Two threads accessing different variables on the same cache
line causes cache line ping-pong:

```rust
struct BadLayout {
    counter_a: AtomicU64,  // Byte 0-7
    counter_b: AtomicU64,  // Byte 8-15  <- Same 64-byte cache line!
}

// Thread 1 writing counter_a and Thread 2 writing counter_b
// will constantly invalidate each other's cache lines
```

Fix with padding:

```rust
#[repr(align(64))]
struct GoodLayout {
    counter_a: AtomicU64,
    _pad: [u8; 56],  // Pad to 64 bytes
}
```

### The MESI Protocol (Cache Coherency)

CPUs use protocols like MESI to keep caches consistent:

- **M**odified: This core has the only valid copy, and it's modified
- **E**xclusive: This core has the only copy, matches memory
- **S**hared: Multiple cores have copies, all match memory
- **I**nvalid: This cache line is stale

When Core 0 writes to a cache line, it broadcasts an "invalidate" message. Other
cores mark their copies Invalid.

### Store Buffers

Writes don't go directly to cache. They go to a store buffer first:

```
Core 0:
  Execute: store x = 1
     |
     v
  Store Buffer: [x = 1] <-- Waits here!
     |
     v (eventually)
  L1 Cache
```

This means other cores might not see the write immediately!

**Example showing the problem**:

```rust
static X: AtomicI32 = AtomicI32::new(0);
static Y: AtomicI32 = AtomicI32::new(0);

// Core 0
X.store(1, Relaxed);  // Goes to store buffer
let y = Y.load(Relaxed);  // Might read from cache before X is visible

// Core 1
Y.store(1, Relaxed);  // Goes to store buffer
let x = X.load(Relaxed);  // Might read from cache before Y is visible

// Possible outcome: y == 0 AND x == 0 (both stores buffered!)
```

### Memory Barriers / Fences

A **memory barrier** (fence) forces ordering. Types:

1. **Load barrier**: All loads before the barrier complete before any load after
2. **Store barrier**: All stores before the barrier complete before any store
   after
3. **Full barrier**: Both load and store barrier

Assembly on x86-64:

```asm
mfence    ; Full memory barrier (expensive)
lfence    ; Load barrier
sfence    ; Store barrier
```

The `lock` prefix on any instruction acts as a full barrier:

```asm
lock addl $0, (%rsp)   ; Common idiom for a barrier
```

### Hardware Atomic Instructions Across Architectures

#### Intel x86/x64: The LOCK Prefix

The `LOCK` prefix on Intel processors has a rich history dating back to the
original 8086 (1978). Initially, it physically locked the bus, preventing other
processors from accessing memory. Modern implementations (post-Pentium 4) are
much more efficient:

**Historical evolution**:

- **8086-486** (1978-1993): `LOCK` asserted the LOCK# signal on the bus,
  physically locking the entire bus
- **Pentium+** (1993+): Introduction of cache locking - if data is in cache,
  only the cache line is locked, not the whole bus
- **Pentium 4+** (2000+): Cache coherency protocols (MESI) make most `LOCK`
  operations efficient without bus locking

**Common LOCK instructions**:

```asm
lock xchg [mem], reg    ; Atomic exchange (LOCK implicit on XCHG with memory)
lock cmpxchg [mem], reg ; Compare-and-swap
lock xadd [mem], reg    ; Exchange and add
lock inc [mem]          ; Atomic increment
lock dec [mem]          ; Atomic decrement
lock add [mem], imm     ; Atomic add
```

**Resources**:

- [Intel SDM Volume 2A: Instruction Set Reference](https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html) -
  Section on LOCK prefix
- [Intel SDM Volume 3A: System Programming Guide](https://cdrdv2-public.intel.com/671200/253668-sdm-vol-3a.pdf) -
  Chapter 8: Memory Ordering

#### AMD x86-64

AMD processors follow the same x86-64 ISA as Intel, so `LOCK` prefix works
identically. However, AMD has some microarchitectural differences:

- **AMD K8 and later**: Introduced HyperTransport with cache coherency
- **AMD Zen architecture** (2017+): Improved cache coherency and atomic
  operation performance

The instruction set is identical to Intel x86-64:

```asm
lock cmpxchg [rax], rbx  ; Same instruction on AMD and Intel
```

**Resources**:

- [AMD64 Architecture Programmer's Manual Volume 2](https://www.amd.com/content/dam/amd/en/documents/processor-tech-docs/programmer-references/24593.pdf) -
  System Programming
- [AMD64 Architecture Programmer's Manual Volume 3](https://www.amd.com/content/dam/amd/en/documents/processor-tech-docs/programmer-references/24594.pdf) -
  General Purpose and System Instructions

#### ARM: Load-Exclusive/Store-Exclusive

ARM uses a fundamentally different approach called **Load-Exclusive (LDREX) /
Store-Exclusive (STREX)** instead of locked read-modify-write:

**ARMv7 (32-bit)**:

```asm
.retry:
    ldrex   r1, [r0]      ; Load-exclusive from address in r0
    add     r1, r1, #1    ; Increment
    strex   r2, r1, [r0]  ; Store-exclusive, r2 = 0 if success
    cmp     r2, #0
    bne     .retry        ; Retry if store failed
```

**ARMv8 (64-bit) - AArch64**:

```asm
.retry:
    ldxr    w1, [x0]      ; Load-exclusive register (32-bit)
    add     w1, w1, #1
    stxr    w2, w1, [x0]  ; Store-exclusive, w2 = 0 if success
    cbnz    w2, .retry    ; Retry if failed
```

**ARMv8.1+**: Introduces **LSE (Large System Extensions)** with true atomic
instructions:

```asm
ldadd   w1, w2, [x0]     ; Atomic add: *x0 += w1, old value -> w2
cas     w1, w2, [x0]     ; Compare-and-swap
swp     w1, w2, [x0]     ; Atomic swap
```

**Memory barriers on ARM**:

```asm
dmb ish     ; Data Memory Barrier - Inner Shareable
dmb ishst   ; DMB - Store only
dmb ishld   ; DMB - Load only
dsb ish     ; Data Synchronization Barrier
isb         ; Instruction Synchronization Barrier
```

**Resources**:

- [ARM Architecture Reference Manual (ARMv8, for ARMv8-A architecture profile)](https://developer.arm.com/documentation/ddi0487/latest/) -
  Official ARM architecture reference
- [ARM Cortex-A Series Programmer's Guide for ARMv8-A](https://developer.arm.com/documentation/den0024/latest/) -
  Chapter on synchronization
- [ARM Barrier Litmus Tests and Cookbook](https://github.com/herd/herdtools7) -
  Formal memory model testing

#### Comparison Table

| Feature          | Intel/AMD x86-64       | ARM (pre-v8.1)      | ARM (v8.1+ LSE)     |
| ---------------- | ---------------------- | ------------------- | ------------------- |
| Atomic primitive | `LOCK` prefix          | `LDREX/STREX` pairs | Atomic instructions |
| Retry on fail    | Hardware automatic     | Software explicit   | Hardware automatic  |
| CAS instruction  | `LOCK CMPXCHG`         | `LDREX/STREX` loop  | `CAS`               |
| Atomic add       | `LOCK XADD`            | `LDREX/STREX` loop  | `LDADD`             |
| Memory model     | TSO (strong)           | Relaxed (weak)      | Relaxed (weak)      |
| Memory barriers  | `MFENCE/LFENCE/SFENCE` | `DMB/DSB/ISB`       | `DMB/DSB/ISB`       |

**Key architectural difference**: x86-64 has a **Total Store Order (TSO)**
memory model (stronger), while ARM has a **relaxed memory model** (weaker,
requires more explicit barriers but allows more optimization).

**Resources**:

- [A Primer on Memory Consistency and Cache Coherence](https://www.morganclaypool.com/doi/abs/10.2200/S00962ED2V01Y201910CAC049) -
  Comprehensive academic resource
- [x86-TSO: A Rigorous and Usable Programmer's Model for x86 Multiprocessors](https://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf) -
  Research paper on x86 memory model
- [ARM and POWER Relaxed Memory Models](https://www.cl.cam.ac.uk/~pes20/weakmemory/) -
  Cambridge research on weak memory models

---

## Memory Ordering

Rust's `std::sync::atomic::Ordering` enum defines memory ordering guarantees:

### Relaxed Ordering

**No ordering guarantees**. Only guarantees atomicity.

```rust
use std::sync::atomic::{AtomicI32, Ordering};

static COUNTER: AtomicI32 = AtomicI32::new(0);

// Thread 1
COUNTER.fetch_add(1, Ordering::Relaxed);

// Thread 2
COUNTER.fetch_add(1, Ordering::Relaxed);
```

Assembly (x86-64):

```asm
; fetch_add with Relaxed
lock xadd [counter], eax   ; Atomic but no ordering
```

**Use case**: Performance counters where exact ordering doesn't matter.

### Acquire-Release Ordering

Creates a **happens-before** relationship:

- **Release**: All previous writes become visible to anyone who acquires
- **Acquire**: All writes from the release become visible

```rust
static DATA: AtomicI32 = AtomicI32::new(0);
static FLAG: AtomicBool = AtomicBool::new(false);

// Thread 1 (Producer)
DATA.store(42, Ordering::Relaxed);         // (1)
FLAG.store(true, Ordering::Release);       // (2) Release

// Thread 2 (Consumer)
while !FLAG.load(Ordering::Acquire) {}     // (3) Acquire
let value = DATA.load(Ordering::Relaxed);  // (4)
// value is guaranteed to be 42!
```

**Happens-before chain**:

- (1) happens-before (2) (program order)
- (2) synchronizes-with (3) (release-acquire)
- (3) happens-before (4) (program order)
- Therefore: (1) happens-before (4)

Assembly difference:

```asm
; Release store (x86-64)
mov [flag], 1        ; Regular store is enough on x86!
                     ; (x86 has strong memory model)

; Acquire load (x86-64)
mov eax, [flag]      ; Regular load is enough on x86!

; On ARM (weaker memory model):
; Release store
dmb ishst            ; Store barrier before store
str [flag], 1

; Acquire load
ldr eax, [flag]
dmb ish              ; Full barrier after load
```

### Sequential Consistency (SeqCst)

**Strongest ordering**. Establishes a single global order of all SeqCst
operations across all threads.

```rust
static X: AtomicI32 = AtomicI32::new(0);
static Y: AtomicI32 = AtomicI32::new(0);

// Thread 1
X.store(1, Ordering::SeqCst);
Y.store(1, Ordering::SeqCst);

// Thread 2
let y = Y.load(Ordering::SeqCst);
let x = X.load(Ordering::SeqCst);

// If y == 1, then x MUST be 1
```

Assembly (x86-64):

```asm
; SeqCst store
mfence               ; Full barrier before store
mov [x], 1

; SeqCst load
mov eax, [x]
mfence               ; Full barrier after load
```

**Cost**: SeqCst is expensive because it requires synchronization across all
cores.

### Ordering Summary Table

| Ordering | Prevents reordering of          | Assembly cost  |
| -------- | ------------------------------- | -------------- |
| Relaxed  | Nothing (atomicity only)        | Cheapest       |
| Acquire  | Loads after with loads before   | Cheap on x86   |
| Release  | Stores before with stores after | Cheap on x86   |
| AcqRel   | Both Acquire and Release        | Moderate       |
| SeqCst   | Everything with everything      | Most expensive |

---

## Atomics and Lock-Free Programming

### Compare-and-Swap (CAS)

The fundamental primitive for lock-free algorithms:

```rust
impl AtomicI32 {
    fn compare_exchange(
        &self,
        current: i32,
        new: i32,
        success: Ordering,
        failure: Ordering
    ) -> Result<i32, i32>
}
```

**Semantics**: Atomically:

1. Read current value
2. If it equals `current`, write `new` and return Ok(current)
3. Otherwise, return Err(actual_value)

Assembly (x86-64):

```asm
mov eax, [current]           ; Expected value
mov ebx, [new]               ; New value
lock cmpxchg [ptr], ebx      ; Compare and exchange
jne failure                  ; Jump if not equal (CAS failed)
```

**ABA Problem**: Value changes A -> B -> A, CAS succeeds but intermediate B
state was missed!

```rust
// Thread 1                    // Thread 2
let old = ptr.load();         // (paused)
// ... does work ...
// Meanwhile:                  ptr.store(B);
                              ptr.store(A);  // Back to A!
// Thread 1 resumes:
ptr.compare_exchange(old, new);  // Succeeds! But state changed
```

Solution: Use tagged pointers or sequence numbers.

### Lock-Free Stack (Treiber Stack)

```rust
use std::sync::atomic::{AtomicPtr, Ordering};
use std::ptr;

struct Node<T> {
    data: T,
    next: *mut Node<T>,
}

pub struct Stack<T> {
    head: AtomicPtr<Node<T>>,
}

impl<T> Stack<T> {
    pub fn new() -> Self {
        Stack {
            head: AtomicPtr::new(ptr::null_mut()),
        }
    }

    pub fn push(&self, data: T) {
        let new_node = Box::into_raw(Box::new(Node {
            data,
            next: ptr::null_mut(),
        }));

        loop {
            let head = self.head.load(Ordering::Acquire);
            unsafe { (*new_node).next = head; }

            // CAS: If head is still the same, update to new_node
            match self.head.compare_exchange(
                head,
                new_node,
                Ordering::Release,  // Success: make new_node visible
                Ordering::Acquire,  // Failure: reload head
            ) {
                Ok(_) => return,  // Success!
                Err(_) => {
                    // Another thread changed head, retry
                }
            }
        }
    }

    pub fn pop(&self) -> Option<T> {
        loop {
            let head = self.head.load(Ordering::Acquire);
            if head.is_null() {
                return None;
            }

            let next = unsafe { (*head).next };

            // Try to update head to next
            match self.head.compare_exchange(
                head,
                next,
                Ordering::Release,
                Ordering::Acquire,
            ) {
                Ok(_) => {
                    // Success! Take ownership of the old head
                    unsafe {
                        let data = ptr::read(&(*head).data);
                        // Note: Memory leak here! Real impl needs
                        // hazard pointers or epoch-based reclamation
                        return Some(data);
                    }
                }
                Err(_) => {
                    // Retry
                }
            }
        }
    }
}
```

**Key insight**: No locks! Multiple threads can push/pop concurrently. If CAS
fails, we just retry.

### Fetch-Add: The Simple Atomic

```rust
static COUNTER: AtomicUsize = AtomicUsize::new(0);

// Atomic increment
COUNTER.fetch_add(1, Ordering::Relaxed);
```

Assembly (x86-64):

```asm
lock xadd [counter], 1   ; Atomic exchange-and-add
```

This is much cheaper than CAS in a loop!

---

## Locks and Mutexes

### Spinlock: The Simplest Lock

```rust
use std::sync::atomic::{AtomicBool, Ordering};

pub struct Spinlock {
    locked: AtomicBool,
}

impl Spinlock {
    pub fn new() -> Self {
        Spinlock {
            locked: AtomicBool::new(false),
        }
    }

    pub fn lock(&self) {
        // Spin until we acquire the lock
        while self.locked.swap(true, Ordering::Acquire) {
            // Busy-wait: keep checking until lock is free
            while self.locked.load(Ordering::Relaxed) {
                std::hint::spin_loop();  // Hint to CPU: we're spinning
            }
        }
    }

    pub fn unlock(&self) {
        self.locked.store(false, Ordering::Release);
    }
}
```

Assembly for `lock()`:

```asm
.retry:
    mov al, 1
    xchg [locked], al        ; Atomic swap
    test al, al
    jz .acquired             ; If old value was 0, we got it!

.spin:
    pause                    ; CPU hint: reduce power, improve perf
    movzx eax, byte [locked]
    test al, al
    jnz .spin                ; Keep spinning if still locked
    jmp .retry               ; Try to acquire again

.acquired:
    ; Lock acquired!
```

**When to use spinlocks**:

- Lock held for very short time (< 100 cycles)
- Cannot sleep (interrupt handlers, real-time systems)

**When NOT to use**:

- Lock held for long time (wastes CPU)
- More threads than cores (pure waste)

### Mutex: OS-Assisted Lock

```rust
// std::sync::Mutex on Linux uses parking_lot,
// which uses futex syscalls

pub struct Mutex<T> {
    state: AtomicU32,  // 0 = unlocked, 1 = locked
    data: UnsafeCell<T>,
}

impl<T> Mutex<T> {
    pub fn lock(&self) -> MutexGuard<T> {
        // Try fast path: lock with CAS
        if self.state.compare_exchange(
            0, 1,
            Ordering::Acquire,
            Ordering::Relaxed
        ).is_ok() {
            // Fast path: got lock immediately!
            return MutexGuard { mutex: self };
        }

        // Slow path: use futex to sleep
        self.lock_slow();
        MutexGuard { mutex: self }
    }

    fn lock_slow(&self) {
        loop {
            // Try to acquire
            if self.state.swap(1, Ordering::Acquire) == 0 {
                return;  // Got it!
            }

            // Failed, sleep via futex
            unsafe {
                libc::syscall(
                    libc::SYS_futex,
                    &self.state,
                    libc::FUTEX_WAIT,
                    1,  // Expected value
                    ptr::null::<libc::timespec>(),  // No timeout
                );
            }
        }
    }

    pub fn unlock(&self) {
        self.state.store(0, Ordering::Release);

        // Wake one waiting thread
        unsafe {
            libc::syscall(
                libc::SYS_futex,
                &self.state,
                libc::FUTEX_WAKE,
                1,  // Wake 1 thread
            );
        }
    }
}
```

**Futex** (Fast Userspace Mutex):

- If lock is free, no syscall (fast path in userspace)
- If contended, syscall to sleep (slow path in kernel)

Assembly for fast path:

```asm
; Try to acquire
xor eax, eax             ; eax = 0 (unlocked)
mov ebx, 1               ; ebx = 1 (locked)
lock cmpxchg [state], ebx
jz .acquired             ; If was 0, we got it!

; Slow path
call futex_wait          ; Syscall to sleep
```

#### Practical Example: std::sync::Mutex with Arc

In practice, Rust's `std::sync::Mutex` is used with `Arc` (Atomic Reference
Counted) to share mutable state between threads:

```rust
use std::sync::{Arc, Mutex};
use std::thread;

fn main() {
    // Arc allows sharing ownership across threads
    // Mutex provides interior mutability
    let counter = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let counter = Arc::clone(&counter);
        let handle = thread::spawn(move || {
            // Lock returns a MutexGuard (RAII)
            let mut num = counter.lock().unwrap();
            *num += 1;
            // Lock automatically released when guard drops
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    println!("Result: {}", *counter.lock().unwrap());
    // Output: Result: 10
}
```

**Key points**:

- `Arc<Mutex<T>>` is the standard pattern for shared mutable state
- `lock()` returns `Result<MutexGuard, PoisonError>`
- Guard automatically releases lock on drop (RAII)
- Lock is poisoned if a thread panics while holding it

#### Example: Sharing Data Between Threads

```rust
use std::sync::{Arc, Mutex};
use std::thread;
use std::collections::HashMap;

fn main() {
    let data = Arc::new(Mutex::new(HashMap::new()));
    let mut handles = vec![];

    for i in 0..5 {
        let data = Arc::clone(&data);
        let handle = thread::spawn(move || {
            let mut map = data.lock().unwrap();
            map.insert(i, i * 2);
            println!("Thread {} inserted ({}, {})", i, i, i * 2);
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.join().unwrap();
    }

    let map = data.lock().unwrap();
    println!("Final map: {:?}", *map);
}
```

#### tokio::sync::Mutex for Async Contexts

**Important**: `std::sync::Mutex` should NOT be held across `.await` points in
async code because it can block the executor. Use `tokio::sync::Mutex` instead:

```rust
use tokio::sync::Mutex;
use std::sync::Arc;

#[tokio::main]
async fn main() {
    let data = Arc::new(Mutex::new(0));
    let mut handles = vec![];

    for _ in 0..10 {
        let data = Arc::clone(&data);
        let handle = tokio::spawn(async move {
            // This is async and won't block the executor
            let mut num = data.lock().await;
            *num += 1;

            // Safe to hold across await points
            tokio::time::sleep(tokio::time::Duration::from_millis(10)).await;
            println!("Value: {}", *num);
        });
        handles.push(handle);
    }

    for handle in handles {
        handle.await.unwrap();
    }

    println!("Final: {}", *data.lock().await);
}
```

**Differences between std::sync::Mutex and tokio::sync::Mutex**:

| Feature                   | std::sync::Mutex            | tokio::sync::Mutex     |
| ------------------------- | --------------------------- | ---------------------- |
| Locking operation         | `lock()` - blocking         | `lock().await` - async |
| Use across await points   | NO - Blocks executor        | YES - Safe             |
| Performance (uncontended) | Faster                      | Slightly slower        |
| Use in sync code          | YES - Preferred             | Possible but slower    |
| Use in async code         | Only if not held over await | YES - Preferred        |

**Rule of thumb**:

- Use `std::sync::Mutex` for synchronous code and CPU-bound tasks
- Use `tokio::sync::Mutex` when you need to hold the lock across `.await` points
- If the critical section is very short and doesn't await, `std::sync::Mutex` is
  fine in async code

### Read-Write Lock (RwLock)

Allows multiple readers OR one writer:

```rust
pub struct RwLock<T> {
    state: AtomicU32,
    // state encoding:
    // 0           = unlocked
    // 1..2^31-1   = N readers
    // 2^31        = write-locked
    data: UnsafeCell<T>,
}
```

State transitions:

```
Unlocked (0)
  |
  +--[read_lock]---> N Readers (1..2^31-1)
  |                      |
  |                      +--[read_unlock]--> Unlocked
  |
  +--[write_lock]--> Write Locked (2^31)
                         |
                         +--[write_unlock]--> Unlocked
```

**Use case**: Data read frequently, written rarely (e.g., config).

---

## Async/Await and Cooperative Concurrency

While threads provide **preemptive concurrency** (the OS decides when to
switch), async/await provides **cooperative concurrency** (tasks voluntarily
yield control). This is fundamentally different from the thread-based
concurrency we've covered so far.

### Threads vs Async: The Fundamental Difference

**Threads** (OS-level concurrency):

- Each thread has its own stack (typically 2MB on Linux)
- OS scheduler preempts threads (time slicing)
- Context switching involves saving/restoring CPU registers
- Overhead: ~10,000 threads max per process
- Blocking operations block the entire thread

**Async Tasks** (application-level concurrency):

- Tasks share stacks through state machines
- Runtime scheduler cooperatively switches tasks
- Context switching is just a function call
- Can handle 10,000+ concurrent tasks easily
- Blocking operations would block the entire executor (DON'T DO THIS!)

### How Async/Await Works: Futures and Polling

At the core, `async fn` returns a `Future`, which is Rust's abstraction for
asynchronous computation:

```rust
pub trait Future {
    type Output;

    fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output>;
}

pub enum Poll<T> {
    Ready(T),
    Pending,
}
```

**Key insight**: Futures are **lazy** - nothing happens until they're polled!

### Compiler Transformation: Async Functions to State Machines

When you write an async function, the compiler transforms it into a state
machine. Here's how:

#### Example 1: Simple Async Function

**What you write**:

```rust
async fn fetch_data(id: u32) -> String {
    let response = http_get(id).await;
    let processed = process(response).await;
    format!("Result: {}", processed)
}
```

**What the compiler generates** (simplified):

```rust
enum FetchDataFuture {
    Start { id: u32 },
    WaitingForHttp { http_future: HttpFuture },
    WaitingForProcess { response: String, process_future: ProcessFuture },
    Done,
}

impl Future for FetchDataFuture {
    type Output = String;

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<String> {
        loop {
            match self.get_mut() {
                FetchDataFuture::Start { id } => {
                    let http_future = http_get(*id);
                    *self.get_mut() = FetchDataFuture::WaitingForHttp { http_future };
                }
                FetchDataFuture::WaitingForHttp { http_future } => {
                    match Pin::new(http_future).poll(cx) {
                        Poll::Ready(response) => {
                            let process_future = process(response.clone());
                            *self.get_mut() = FetchDataFuture::WaitingForProcess {
                                response,
                                process_future,
                            };
                        }
                        Poll::Pending => return Poll::Pending,
                    }
                }
                FetchDataFuture::WaitingForProcess { response, process_future } => {
                    match Pin::new(process_future).poll(cx) {
                        Poll::Ready(processed) => {
                            let result = format!("Result: {}", processed);
                            *self.get_mut() = FetchDataFuture::Done;
                            return Poll::Ready(result);
                        }
                        Poll::Pending => return Poll::Pending,
                    }
                }
                FetchDataFuture::Done => panic!("polled after completion"),
            }
        }
    }
}
```

**Key transformations**:

1. Each `.await` point becomes a state transition
2. Local variables that live across `.await` are stored in the state machine
3. The state machine implements `Future`
4. `poll()` resumes from the last `.await` point

#### Inspecting the Actual Generated Code

You can see what the compiler actually generates using several tools:

**Method 1: cargo-expand** (shows macro-expanded code)

Install and run:

```bash
cargo install cargo-expand
cargo expand --lib my_module
```

Example output for a simple async function:

```rust
// Your code:
async fn add(a: i32, b: i32) -> i32 {
    a + b
}

// Expanded by cargo-expand (simplified):
fn add(a: i32, b: i32) -> impl Future<Output = i32> {
    async move {
        a + b
    }
}
```

**Method 2: MIR (Mid-level Intermediate Representation)**

The MIR shows the state machine more clearly:

```bash
cargo rustc -- --emit=mir
# Output in target/debug/deps/*.mir
```

**Method 3: Compiler Explorer (Godbolt)**

Visit [Rust Playground](https://play.rust-lang.org/) or
[Compiler Explorer](https://godbolt.org/) and enable "MIR" or "HIR" output.

**Example inspection**:

```rust
// File: src/main.rs
async fn example(x: i32) -> i32 {
    let y = expensive_call().await;
    x + y
}

async fn expensive_call() -> i32 {
    42
}
```

Run `cargo expand`:

```bash
$ cargo expand
```

You'll see something like (heavily simplified):

```rust
fn example(x: i32) -> impl Future<Output = i32> {
    enum __Example {
        __Start { x: i32 },
        __WaitingExpensiveCall { x: i32, __fut: /* expensive_call future */ },
    }

    impl Future for __Example {
        type Output = i32;
        fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<i32> {
            // State machine implementation
        }
    }

    __Example::__Start { x }
}
```

**Method 4: -Zdump-mir (nightly only)**

For even more detail:

```bash
RUSTFLAGS="-Z dump-mir=all" cargo +nightly build
# Generates .mir files in target/debug/deps/
```

**Practical example to try**:

Create a simple project and inspect:

```rust
// src/main.rs
async fn multi_await() -> i32 {
    let a = async { 1 }.await;
    let b = async { 2 }.await;
    let c = async { 3 }.await;
    a + b + c
}

fn main() {
    println!("Use cargo-expand to see the generated code!");
}
```

Then run:

```bash
cargo expand
```

You'll see the compiler generates an enum with 4 states (Start, AfterFirst,
AfterSecond, AfterThird) and a complex `poll` implementation that transitions
between them.

**What you'll discover**:

- The exact enum variants for each state
- How the compiler stores variables that cross `.await` boundaries
- The `poll` method that implements the state transitions
- Memory layout optimizations (enums are usually the size of the largest
  variant)

#### Example 2: Visualizing State Transitions

```rust
async fn example() {
    println!("State 0: Start");

    task1().await;  // Await point 1
    println!("State 1: After task1");

    task2().await;  // Await point 2
    println!("State 2: After task2");

    task3().await;  // Await point 3
    println!("State 3: Done");
}
```

**State machine**:

```
State 0 (Start)
    |
    v
Poll task1 --> Pending? Return Poll::Pending
    |                         ^
    | Ready                   |
    v                         |
State 1                       |
    |                         |
    v                         |
Poll task2 --> Pending? ------+
    |
    | Ready
    v
State 2
    |
    v
Poll task3 --> Pending? Return Poll::Pending
    |                         ^
    | Ready                   |
    v                         |
State 3 (Done) ---------------+
```

### How Tokio Works: The Runtime

Tokio is an async runtime that provides:

1. **Executor/Scheduler**: Polls futures and decides what to run
2. **Reactor**: Handles I/O events (epoll on Linux, kqueue on macOS)
3. **Timer**: Manages time-based operations
4. **Task spawner**: Creates new async tasks

#### Tokio Architecture

```
┌─────────────────────────────────────────────┐
│           Your Async Code                   │
│    (async fn, .await, tokio::spawn)         │
└─────────────────┬───────────────────────────┘
                  │
┌─────────────────▼───────────────────────────┐
│         Tokio Runtime                       │
│  ┌──────────────────────────────────────┐   │
│  │  Executor (Work-Stealing Scheduler)  │   │
│  │  - Multiple worker threads           │   │
│  │  - Task queues                       │   │
│  │  - Polls ready futures               │   │
│  └──────────────┬───────────────────────┘   │
│                 │                            │
│  ┌──────────────▼───────────────────────┐   │
│  │  Reactor (Event Loop)                │   │
│  │  - epoll/kqueue for I/O              │   │
│  │  - Wakes futures when I/O ready      │   │
│  └──────────────────────────────────────┘   │
└─────────────────────────────────────────────┘
                  │
┌─────────────────▼───────────────────────────┐
│         Operating System                    │
│  - Network sockets                          │
│  - File descriptors                         │
│  - System calls                             │
└─────────────────────────────────────────────┘
```

#### Example: How a Task is Scheduled

```rust
#[tokio::main]
async fn main() {
    let handle = tokio::spawn(async {
        println!("Task started");
        tokio::time::sleep(Duration::from_secs(1)).await;
        println!("Task finished");
        42
    });

    let result = handle.await.unwrap();
    println!("Result: {}", result);
}
```

**Execution flow**:

1. `tokio::spawn()` creates a new task and adds it to the executor's queue
2. Executor polls the task's future
3. Future prints "Task started"
4. Future hits `.await` on `sleep()`, returns `Poll::Pending`
5. Executor registers a timer with the reactor
6. Executor moves to poll other ready tasks
7. After 1 second, timer fires, reactor wakes the task
8. Executor polls the task again
9. Future prints "Task finished", returns `Poll::Ready(42)`
10. `handle.await` returns the result

### The Waker Mechanism

When a future returns `Poll::Pending`, it must register a `Waker` so it can be
polled again when ready:

```rust
use std::task::{Context, Poll, Waker};
use std::future::Future;
use std::pin::Pin;

struct TimerFuture {
    waker: Option<Waker>,
    deadline: Instant,
}

impl Future for TimerFuture {
    type Output = ();

    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<()> {
        if Instant::now() >= self.deadline {
            return Poll::Ready(());
        }

        // Store the waker so we can wake this task later
        self.waker = Some(cx.waker().clone());

        // Register with reactor to wake us when time arrives
        register_timer(self.deadline, self.waker.clone().unwrap());

        Poll::Pending
    }
}
```

When the timer expires, the reactor calls `waker.wake()`, which tells the
executor to poll this future again.

### Practical Example: Concurrent HTTP Requests

**With threads** (blocking):

```rust
use std::thread;

fn main() {
    let handles: Vec<_> = (0..100).map(|i| {
        thread::spawn(move || {
            // Each thread has its own stack (~2MB)
            let response = reqwest::blocking::get(format!("https://api.example.com/{}", i))
                .unwrap();
            response.text().unwrap()
        })
    }).collect();

    for handle in handles {
        let result = handle.join().unwrap();
        println!("Got: {}", result);
    }
}
// Memory usage: ~100 threads × 2MB = ~200MB just for stacks!
```

**With async/await** (non-blocking):

```rust
#[tokio::main]
async fn main() {
    let mut tasks = vec![];

    for i in 0..100 {
        tasks.push(tokio::spawn(async move {
            // Tasks share stacks via state machines
            let response = reqwest::get(format!("https://api.example.com/{}", i))
                .await
                .unwrap();
            response.text().await.unwrap()
        }));
    }

    for task in tasks {
        let result = task.await.unwrap();
        println!("Got: {}", result);
    }
}
// Memory usage: A few KB per task, ~hundreds of KB total
```

### Common Pitfalls

#### 1. Blocking the Executor

**BAD** - Blocks all tasks on this thread:

```rust
tokio::spawn(async {
    // This blocks the executor thread!
    std::thread::sleep(Duration::from_secs(1));
});
```

**GOOD** - Cooperative yield:

```rust
tokio::spawn(async {
    // This yields to other tasks
    tokio::time::sleep(Duration::from_secs(1)).await;
});
```

#### 2. CPU-Bound Work

**BAD** - Starves I/O tasks:

```rust
tokio::spawn(async {
    // Heavy CPU work blocks executor
    compute_fibonacci(50);
});
```

**GOOD** - Use blocking thread pool:

```rust
tokio::spawn(async {
    let result = tokio::task::spawn_blocking(|| {
        // Runs on dedicated blocking thread pool
        compute_fibonacci(50)
    }).await.unwrap();
});
```

#### 3. Not Holding Locks Across Await

**BAD** - std::sync::Mutex blocks executor:

```rust
use std::sync::Mutex;

let mutex = Arc::new(Mutex::new(0));
tokio::spawn(async move {
    let mut data = mutex.lock().unwrap();  // Acquires lock
    *data += 1;
    some_async_operation().await;  // DEADLOCK RISK! Holds lock across await
});
```

**GOOD** - Use tokio::sync::Mutex or drop guard before await:

```rust
use tokio::sync::Mutex;

let mutex = Arc::new(Mutex::new(0));
tokio::spawn(async move {
    let mut data = mutex.lock().await;  // Async lock
    *data += 1;
    some_async_operation().await;  // Safe - async-aware lock
});
```

### Performance Characteristics

| Operation              | Threads            | Async/Await          |
| ---------------------- | ------------------ | -------------------- |
| Task creation overhead | ~100 microseconds  | ~100 nanoseconds     |
| Memory per task        | ~2MB (stack)       | ~2KB (state machine) |
| Context switch cost    | ~1-10 microseconds | ~10-100 nanoseconds  |
| Max concurrent tasks   | ~10,000            | 100,000+             |
| Best for               | CPU-bound work     | I/O-bound work       |

### Resources

- [Tokio Tutorial](https://tokio.rs/tokio/tutorial) - Official Tokio guide
- [Async Book](https://rust-lang.github.io/async-book/) - Official Rust async
  programming book
- [Pin and suffering](https://fasterthanli.me/articles/pin-and-suffering) - Deep
  dive into Pin and async internals
- [How Rust optimizes async/await](https://tmandry.gitlab.io/blog/posts/optimizing-await-1/) -
  Compiler optimizations for async
- [Tokio Internals: Understanding Rust's Asynchronous I/O Framework](https://cafbit.com/post/tokio_internals/) -
  How Tokio works under the hood

---

## Deadlocks, Livelocks, and Starvation

### Deadlock

**Definition**: Two or more threads waiting for each other forever.

Classic example (Dining Philosophers):

```rust
let fork1 = Arc::new(Mutex::new(()));
let fork2 = Arc::new(Mutex::new(()));

// Thread 1
let _f1 = fork1.lock();
let _f2 = fork2.lock();  // Waits for Thread 2

// Thread 2
let _f2 = fork2.lock();
let _f1 = fork1.lock();  // Waits for Thread 1
// DEADLOCK!
```

**Necessary conditions** (all must hold):

1. Mutual exclusion
2. Hold and wait
3. No preemption
4. Circular wait

**Prevention strategies**:

1. **Lock ordering**: Always acquire locks in same order

   ```rust
   // Use address ordering
   let (first, second) = if &*lock1 as *const _ < &*lock2 as *const _ {
       (&lock1, &lock2)
   } else {
       (&lock2, &lock1)
   };
   let _g1 = first.lock();
   let _g2 = second.lock();
   ```

2. **Try-lock**: Use timeouts

   ```rust
   loop {
       let g1 = lock1.lock();
       if let Some(g2) = lock2.try_lock() {
           // Got both!
           break;
       }
       drop(g1);  // Release and retry
       std::thread::sleep(Duration::from_millis(1));
   }
   ```

3. **Lock-free algorithms**: Avoid locks entirely

### Livelock

**Definition**: Threads actively doing work but making no progress.

Example:

```rust
// Both threads trying to be polite
let (lock1, lock2) = // ...

// Thread 1
loop {
    let g1 = lock1.lock();
    if let Some(g2) = lock2.try_lock() {
        break;  // Success
    }
    drop(g1);  // "After you!"
    std::thread::yield_now();
}

// Thread 2 doing the same thing
// Both keep releasing and retrying, never making progress
```

Solution: Add randomized backoff.

### Starvation

**Definition**: A thread is perpetually denied access to a resource.

Example with spinlock:

```rust
// High-priority thread keeps reacquiring lock
loop {
    let _guard = lock.lock();
    do_work();
    drop(_guard);
    // Immediately reacquire!
}
// Low-priority thread never gets in
```

Solutions:

- Fair locks (ticket locks, MCS locks)
- OS scheduler priority adjustments

---

## Advanced Topics

### The Happens-Before Relation

Formal definition of ordering in concurrent programs.

**Happens-before (->)** is a partial order where:

1. **Program order**: Within a thread, A -> B if A comes before B
2. **Synchronizes-with**: Release -> Acquire on same atomic
3. **Transitivity**: If A -> B and B -> C, then A -> C

Example:

```rust
static X: AtomicI32 = AtomicI32::new(0);
static Y: AtomicI32 = AtomicI32::new(0);

// Thread 1
X.store(1, Relaxed);           // A
Y.store(1, Release);           // B

// Thread 2
while Y.load(Acquire) == 0 {}  // C
let x = X.load(Relaxed);       // D

// A -> B (program order)
// B -> C (synchronizes-with)
// C -> D (program order)
// Therefore: A -> D (transitivity)
// So x MUST be 1
```

### Data Races vs Race Conditions

**Data Race** (undefined behavior in C/C++, compile error in Rust): Two threads
access same memory location, at least one is a write, without synchronization.

```rust
// This won't compile in Rust!
let mut x = 0;
std::thread::spawn(|| {
    x = 1;  // Error: can't capture mutable reference
});
x = 2;
```

**Race Condition**: Program behavior depends on timing. May or may not be a bug.

```rust
static COUNTER: AtomicI32 = AtomicI32::new(0);

// Thread 1
if COUNTER.load(Relaxed) == 0 {
    COUNTER.store(1, Relaxed);
}

// Thread 2 (same code)
// Race condition: both might read 0 and write 1
// But no data race: all accesses are synchronized
```

### Memory Reclamation in Lock-Free Code

The core problem: When can we free memory?

```rust
// Thread 1 pops node
let node = stack.pop();  // Got node pointer

// Thread 2 might still be reading this node!
// Can't free yet!
```

Solutions:

1. **Reference Counting**: `Arc<T>` (has overhead)
2. **Hazard Pointers**: Thread announces what it's using
3. **Epoch-Based Reclamation** (EBR): Defer frees to safe points

Example with `crossbeam::epoch`:

```rust
use crossbeam_epoch::{self as epoch, Atomic, Owned};

pub struct Stack<T> {
    head: Atomic<Node<T>>,
}

impl<T> Stack<T> {
    pub fn pop(&self) -> Option<T> {
        let guard = epoch::pin();  // Enter epoch
        loop {
            let head = self.head.load(Acquire, &guard);
            // ... CAS to remove head ...

            // Don't free immediately!
            unsafe {
                guard.defer_destroy(head);  // Free when safe
            }
        }
    }
}
```

### Lock-Free vs Wait-Free

**Lock-free**: System makes progress even if some threads stall. At least one
thread makes progress in bounded steps.

**Wait-free**: Every thread makes progress in bounded steps. Much stronger
guarantee!

Example:

```rust
// Lock-free (CAS loop might spin forever for one thread)
while cas_fails() {
    // This thread might starve, but others make progress
}

// Wait-free (guaranteed progress)
let slot = fetch_add(index, 1);  // Always succeeds in O(1)
array[slot] = value;
```

Wait-free is much harder to achieve!

---

## Practical Guidelines

### When to Use What

| Scenario                          | Use                   |
| --------------------------------- | --------------------- |
| Simple counter                    | `AtomicU64` + Relaxed |
| Producer-consumer                 | Acquire-Release       |
| Shared config (read-heavy)        | `RwLock`              |
| Short critical section (< 100 cy) | Spinlock              |
| Long critical section             | `Mutex`               |
| Need fairness                     | OS mutex              |
| Maximum performance               | Lock-free             |
| Guaranteed progress               | Wait-free             |

### Rust's Safety Guarantees

Rust prevents data races at compile time through its ownership and type system:

#### Example 1: Compiler Prevents Unsafe Sharing

```rust
let mut x = 0;

// Won't compile: can't capture mutable reference in thread
std::thread::spawn(|| {
    x += 1;  // Error: closure may outlive the current function
});
x += 1;  // Error: x borrowed by closure above
```

**Compiler error**:

```
error[E0373]: closure may outlive the current function
```

#### Example 2: Fix with Atomics (Lock-Free)

For simple counters, use atomics:

```rust
use std::sync::Arc;
use std::sync::atomic::{AtomicI32, Ordering};
use std::thread;

let x = Arc::new(AtomicI32::new(0));
let mut handles = vec![];

for _ in 0..10 {
    let x = Arc::clone(&x);
    let handle = thread::spawn(move || {
        x.fetch_add(1, Ordering::Relaxed);  // Lock-free!
    });
    handles.push(handle);
}

for handle in handles {
    handle.join().unwrap();
}

println!("Final value: {}", x.load(Ordering::Relaxed));
// Output: Final value: 10
```

#### Example 3: Fix with Arc<Mutex<T>> (General Solution)

For complex shared state, use `Arc<Mutex<T>>`:

```rust
use std::sync::{Arc, Mutex};
use std::thread;

let x = Arc::new(Mutex::new(0));
let mut handles = vec![];

for _ in 0..10 {
    let x = Arc::clone(&x);
    let handle = thread::spawn(move || {
        let mut num = x.lock().unwrap();
        *num += 1;
        // Lock automatically released when `num` goes out of scope
    });
    handles.push(handle);
}

for handle in handles {
    handle.join().unwrap();
}

println!("Final value: {}", *x.lock().unwrap());
// Output: Final value: 10
```

**Why Arc?**

- `Rc<T>` is not `Send`, so it can't cross thread boundaries
- `Arc<T>` uses atomic reference counting, making it `Send + Sync`
- The compiler enforces this at compile time!

```rust
use std::rc::Rc;
use std::sync::Mutex;

let x = Rc::new(Mutex::new(0));  // Rc is not thread-safe

std::thread::spawn(move || {
    // Error: `Rc<Mutex<i32>>` cannot be sent between threads safely
    let mut num = x.lock().unwrap();
    *num += 1;
});
```

#### What Rust CAN Prevent

- **Data races** (undefined behavior from unsynchronized access)
- **Use-after-free** (dangling pointers)
- **Iterator invalidation**
- **Sending non-thread-safe types across threads**

#### What Rust CANNOT Prevent

- **Deadlocks** (circular wait on locks)
- **Race conditions** (logic bugs from timing dependencies)
- **Performance bugs** (excessive locking, false sharing)
- **Logical errors** (incorrect use of correct synchronization)

---

## Exercises

1. Implement a ticket lock (fair spinlock)
2. Implement a lock-free queue (Michael-Scott queue)
3. Write a program with a race condition but no data race
4. Prove why double-checked locking is broken (in C++)
5. Implement SeqLock for read-heavy workloads

---

## Further Reading

- ["The Art of Multiprocessor Programming"](https://www.sciencedirect.com/book/9780124159501/the-art-of-multiprocessor-programming)
  by Herlihy & Shavit
- ["Linux Kernel Development"](https://www.amazon.com/Linux-Kernel-Development-Robert-Love/dp/0672329468)
  by Robert Love (Chapter on locking)
- ["Is Parallel Programming Hard, And, If So, What Can You Do About It?"](https://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html)
  by Paul McKenney (free PDF)
- [Intel Software Developer Manual, Volume 3](https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html)
  (Memory Ordering)
- [ARM Architecture Reference Manual](https://developer.arm.com/documentation/ddi0487/latest/)
  (Memory Model)
- [The Rust Nomicon: Atomics chapter](https://doc.rust-lang.org/nomicon/atomics.html)
